{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overfitting Exercise\n",
    "In this exercise, we'll build a model that, as you'll see, dramatically overfits the training data. This will allow you to see what overfitting can \"look like\" in practice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import math\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this exercise, we'll use gradient boosted trees. In order to implement this model, we'll use the XGBoost package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pip\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/43/84/23ed6a1796480a6f1a2d38f2802901d078266bda38388954d01d3f2e821d/pip-20.1.1-py2.py3-none-any.whl (1.5MB)\n",
      "\u001b[K    100% |████████████████████████████████| 1.5MB 11.1MB/s ta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: pip\n",
      "  Found existing installation: pip 18.1\n",
      "    Uninstalling pip-18.1:\n",
      "      Successfully uninstalled pip-18.1\n",
      "Successfully installed pip-20.1.1\n",
      "Collecting xgboost\n",
      "  Downloading xgboost-1.1.1-py3-none-manylinux2010_x86_64.whl (127.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 127.6 MB 11 kB/s s eta 0:00:01  |▌                               | 2.1 MB 3.4 MB/s eta 0:00:38     |█▌                              | 5.8 MB 3.4 MB/s eta 0:00:37     |█▉                              | 7.2 MB 3.4 MB/s eta 0:00:36     |██▌                             | 10.0 MB 3.4 MB/s eta 0:00:36     |██▉                             | 11.3 MB 3.4 MB/s eta 0:00:35     |███▌                            | 14.1 MB 3.4 MB/s eta 0:00:34     |████                            | 15.6 MB 3.4 MB/s eta 0:00:34     |████▎                           | 16.9 MB 3.4 MB/s eta 0:00:33     |█████▋                          | 22.3 MB 3.4 MB/s eta 0:00:32     |██████                          | 23.7 MB 27.0 MB/s eta 0:00:04     |████████▏                       | 32.6 MB 27.0 MB/s eta 0:00:04     |█████████                       | 36.3 MB 27.0 MB/s eta 0:00:04     |█████████▍                      | 37.5 MB 27.0 MB/s eta 0:00:04     |█████████▊                      | 38.7 MB 27.0 MB/s eta 0:00:04     |████████████▏                   | 48.3 MB 24.1 MB/s eta 0:00:04     |████████████▍                   | 49.5 MB 24.1 MB/s eta 0:00:04     |████████████▊                   | 50.7 MB 24.1 MB/s eta 0:00:04     |███████████████▍                | 61.2 MB 24.1 MB/s eta 0:00:03     |████████████████                | 63.5 MB 24.1 MB/s eta 0:00:03     |██████████████████▌             | 73.6 MB 22.5 MB/s eta 0:00:03     |███████████████████▌            | 77.9 MB 22.5 MB/s eta 0:00:03     |███████████████████▉            | 79.0 MB 22.5 MB/s eta 0:00:03     |█████████████████████           | 83.3 MB 22.5 MB/s eta 0:00:02     |██████████████████████          | 87.6 MB 22.5 MB/s eta 0:00:02     |██████████████████████▎         | 88.7 MB 22.5 MB/s eta 0:00:02     |███████████████████████▉        | 95.0 MB 21.6 MB/s eta 0:00:02     |████████████████████████▍       | 97.0 MB 21.6 MB/s eta 0:00:02     |█████████████████████████▍      | 101.0 MB 21.6 MB/s eta 0:00:02     |██████████████████████████      | 104.0 MB 21.6 MB/s eta 0:00:02     |███████████████████████████     | 108.0 MB 21.6 MB/s eta 0:00:01     |█████████████████████████████▌  | 117.4 MB 22.7 MB/s eta 0:00:01     |██████████████████████████████▉ | 122.8 MB 22.7 MB/s eta 0:00:01     |███████████████████████████████▏| 124.1 MB 22.7 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: scipy in /opt/conda/lib/python3.6/site-packages (from xgboost) (1.2.1)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.6/site-packages (from xgboost) (1.12.1)\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-1.1.1\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pip\n",
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we define a few helper functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of rows in a dataframe\n",
    "def nrow(df): \n",
    "    return(len(df.index))\n",
    "\n",
    "# number of columns in a dataframe\n",
    "def ncol(df): \n",
    "    return(len(df.columns))\n",
    "\n",
    "# flatten nested lists/arrays\n",
    "flatten = lambda l: [item for sublist in l for item in sublist]\n",
    "\n",
    "# combine multiple arrays into a single list\n",
    "def c(*args):\n",
    "    return(flatten([item for item in args]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise, we're going to try to predict the returns of the S&P 500 ETF. This may be a futile endeavor, since many experts consider the S&P 500 to be essentially unpredictable, but it will serve well for the purpose of this exercise. The following cell loads the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"SPYZ.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the data file has four columns, `Date`, `Close`, `Volume` and `Return`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Return</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1999-12-31</td>\n",
       "      <td>146.8750</td>\n",
       "      <td>3172700</td>\n",
       "      <td>0.001598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000-01-03</td>\n",
       "      <td>145.4375</td>\n",
       "      <td>8164300</td>\n",
       "      <td>-0.009787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000-01-04</td>\n",
       "      <td>139.7500</td>\n",
       "      <td>8089800</td>\n",
       "      <td>-0.039106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2000-01-05</td>\n",
       "      <td>140.0000</td>\n",
       "      <td>12177900</td>\n",
       "      <td>0.001789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000-01-06</td>\n",
       "      <td>137.7500</td>\n",
       "      <td>6227200</td>\n",
       "      <td>-0.016071</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date     Close    Volume    Return\n",
       "0  1999-12-31  146.8750   3172700  0.001598\n",
       "1  2000-01-03  145.4375   8164300 -0.009787\n",
       "2  2000-01-04  139.7500   8089800 -0.039106\n",
       "3  2000-01-05  140.0000  12177900  0.001789\n",
       "4  2000-01-06  137.7500   6227200 -0.016071"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = nrow(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll form our predictors/features. In the cells below, we create four types of features. We also use a parameter, `K`, to set the number of each type of feature to build. With a `K` of 25, 100 features will be created. This should already seem like a lot of features, and alert you to the potential that the model will be overfit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors = []\n",
    "\n",
    "# we'll create a new DataFrame to hold the data that we'll use to train the model\n",
    "# we'll create it from the `Return` column in the original DataFrame, but rename that column `y`\n",
    "model_df = pd.DataFrame(data = df['Return']).rename(columns = {\"Return\" : \"y\"})\n",
    "\n",
    "# IMPORTANT: this sets how many of each of the following four predictors to create\n",
    "K = 25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, you write the code to create the four types of predictors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for L in range(1,K+1): \n",
    "    # this predictor is just the return L days ago, where L goes from 1 to K\n",
    "    # these predictors will be named `R1`, `R2`, etc.\n",
    "    pR = \"\".join([\"R\",str(L)]) \n",
    "    predictors.append(pR)\n",
    "    for i in range(K+1,n): \n",
    "        # TODO: fill in the code to assign the return from L days before to the ith row of this predictor in `model_df`\n",
    "        model_df.loc[i, pR] = df.loc[i-L,\"Return\"]\n",
    "\n",
    "    # this predictor is the return L days ago, squared, where L goes from 1 to K\n",
    "    # these predictors will be named `Rsq1`, `Rsq2`, etc.\n",
    "    pR2 = \"\".join([\"Rsq\",str(L)])\n",
    "    predictors.append(pR2)\n",
    "    for i in range(K+1,n): \n",
    "        # TODO: fill in the code to assign the squared return from L days before to the ith row of this predictor \n",
    "        # in `model_df`\n",
    "        model_df.loc[i, pR2] = df.loc[i-L,\"Return\"]**2\n",
    "\n",
    "    # this predictor is the log volume L days ago, where L goes from 1 to K\n",
    "    # these predictors will be named `V1`, `V2`, etc.\n",
    "    pV = \"\".join([\"V\",str(L)])\n",
    "    predictors.append(pV)\n",
    "    for i in range(K+1,n): \n",
    "        # TODO: fill in the code to assign the log of the volume from L days before to the ith row of this predictor \n",
    "        # in `model_df`\n",
    "        # Add 1 to the volume before taking the log\n",
    "        model_df.loc[i, pV] = np.log(1+df.loc[i-L,\"Volume\"])\n",
    "\n",
    "    # this predictor is the product of the return and the log volume from L days ago, where L goes from 1 to K\n",
    "    # these predictors will be named `RV1`, `RV2`, etc.\n",
    "    pRV = \"\".join([\"RV\",str(L)])\n",
    "    predictors.append(pRV)\n",
    "    for i in range(K+1,n): \n",
    "        # TODO: fill in the code to assign the product of the return and the log volume from L days before to the\n",
    "        # ith row of this predictor in `model_df`\n",
    "        model_df.loc[i, pRV] = df.loc[i-L,\"Return\"]*np.log(1+df.loc[i-L,\"Volume\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the predictors we've created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>R1</th>\n",
       "      <th>Rsq1</th>\n",
       "      <th>V1</th>\n",
       "      <th>RV1</th>\n",
       "      <th>R2</th>\n",
       "      <th>Rsq2</th>\n",
       "      <th>V2</th>\n",
       "      <th>RV2</th>\n",
       "      <th>R3</th>\n",
       "      <th>...</th>\n",
       "      <th>V23</th>\n",
       "      <th>RV23</th>\n",
       "      <th>R24</th>\n",
       "      <th>Rsq24</th>\n",
       "      <th>V24</th>\n",
       "      <th>RV24</th>\n",
       "      <th>R25</th>\n",
       "      <th>Rsq25</th>\n",
       "      <th>V25</th>\n",
       "      <th>RV25</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0.016304</td>\n",
       "      <td>-0.014726</td>\n",
       "      <td>0.000217</td>\n",
       "      <td>15.892349</td>\n",
       "      <td>-0.234024</td>\n",
       "      <td>-0.007529</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>16.198698</td>\n",
       "      <td>-0.121956</td>\n",
       "      <td>-0.018688</td>\n",
       "      <td>...</td>\n",
       "      <td>15.959991</td>\n",
       "      <td>0.076664</td>\n",
       "      <td>-0.009302</td>\n",
       "      <td>0.000087</td>\n",
       "      <td>15.695540</td>\n",
       "      <td>-0.145995</td>\n",
       "      <td>0.026421</td>\n",
       "      <td>0.000698</td>\n",
       "      <td>16.209371</td>\n",
       "      <td>0.428273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>-0.017157</td>\n",
       "      <td>0.016304</td>\n",
       "      <td>0.000266</td>\n",
       "      <td>16.221058</td>\n",
       "      <td>0.264474</td>\n",
       "      <td>-0.014726</td>\n",
       "      <td>0.000217</td>\n",
       "      <td>15.892349</td>\n",
       "      <td>-0.234024</td>\n",
       "      <td>-0.007529</td>\n",
       "      <td>...</td>\n",
       "      <td>16.372203</td>\n",
       "      <td>-0.177882</td>\n",
       "      <td>0.004804</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>15.959991</td>\n",
       "      <td>0.076664</td>\n",
       "      <td>-0.009302</td>\n",
       "      <td>0.000087</td>\n",
       "      <td>15.695540</td>\n",
       "      <td>-0.145995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>0.001133</td>\n",
       "      <td>-0.017157</td>\n",
       "      <td>0.000294</td>\n",
       "      <td>15.929221</td>\n",
       "      <td>-0.273290</td>\n",
       "      <td>0.016304</td>\n",
       "      <td>0.000266</td>\n",
       "      <td>16.221058</td>\n",
       "      <td>0.264474</td>\n",
       "      <td>-0.014726</td>\n",
       "      <td>...</td>\n",
       "      <td>16.461827</td>\n",
       "      <td>0.683503</td>\n",
       "      <td>-0.010865</td>\n",
       "      <td>0.000118</td>\n",
       "      <td>16.372203</td>\n",
       "      <td>-0.177882</td>\n",
       "      <td>0.004804</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>15.959991</td>\n",
       "      <td>0.076664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>0.034194</td>\n",
       "      <td>0.001133</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>15.387039</td>\n",
       "      <td>0.017437</td>\n",
       "      <td>-0.017157</td>\n",
       "      <td>0.000294</td>\n",
       "      <td>15.929221</td>\n",
       "      <td>-0.273290</td>\n",
       "      <td>0.016304</td>\n",
       "      <td>...</td>\n",
       "      <td>15.858172</td>\n",
       "      <td>-0.178954</td>\n",
       "      <td>0.041520</td>\n",
       "      <td>0.001724</td>\n",
       "      <td>16.461827</td>\n",
       "      <td>0.683503</td>\n",
       "      <td>-0.010865</td>\n",
       "      <td>0.000118</td>\n",
       "      <td>16.372203</td>\n",
       "      <td>-0.177882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>0.000657</td>\n",
       "      <td>0.034194</td>\n",
       "      <td>0.001169</td>\n",
       "      <td>15.494960</td>\n",
       "      <td>0.529838</td>\n",
       "      <td>0.001133</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>15.387039</td>\n",
       "      <td>0.017437</td>\n",
       "      <td>-0.017157</td>\n",
       "      <td>...</td>\n",
       "      <td>16.562480</td>\n",
       "      <td>-0.054770</td>\n",
       "      <td>-0.011285</td>\n",
       "      <td>0.000127</td>\n",
       "      <td>15.858172</td>\n",
       "      <td>-0.178954</td>\n",
       "      <td>0.041520</td>\n",
       "      <td>0.001724</td>\n",
       "      <td>16.461827</td>\n",
       "      <td>0.683503</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            y        R1      Rsq1         V1       RV1        R2      Rsq2  \\\n",
       "100  0.016304 -0.014726  0.000217  15.892349 -0.234024 -0.007529  0.000057   \n",
       "101 -0.017157  0.016304  0.000266  16.221058  0.264474 -0.014726  0.000217   \n",
       "102  0.001133 -0.017157  0.000294  15.929221 -0.273290  0.016304  0.000266   \n",
       "103  0.034194  0.001133  0.000001  15.387039  0.017437 -0.017157  0.000294   \n",
       "104  0.000657  0.034194  0.001169  15.494960  0.529838  0.001133  0.000001   \n",
       "\n",
       "            V2       RV2        R3    ...           V23      RV23       R24  \\\n",
       "100  16.198698 -0.121956 -0.018688    ...     15.959991  0.076664 -0.009302   \n",
       "101  15.892349 -0.234024 -0.007529    ...     16.372203 -0.177882  0.004804   \n",
       "102  16.221058  0.264474 -0.014726    ...     16.461827  0.683503 -0.010865   \n",
       "103  15.929221 -0.273290  0.016304    ...     15.858172 -0.178954  0.041520   \n",
       "104  15.387039  0.017437 -0.017157    ...     16.562480 -0.054770 -0.011285   \n",
       "\n",
       "        Rsq24        V24      RV24       R25     Rsq25        V25      RV25  \n",
       "100  0.000087  15.695540 -0.145995  0.026421  0.000698  16.209371  0.428273  \n",
       "101  0.000023  15.959991  0.076664 -0.009302  0.000087  15.695540 -0.145995  \n",
       "102  0.000118  16.372203 -0.177882  0.004804  0.000023  15.959991  0.076664  \n",
       "103  0.001724  16.461827  0.683503 -0.010865  0.000118  16.372203 -0.177882  \n",
       "104  0.000127  15.858172 -0.178954  0.041520  0.001724  16.461827  0.683503  \n",
       "\n",
       "[5 rows x 101 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_df.iloc[100:105,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>R1</th>\n",
       "      <th>Rsq1</th>\n",
       "      <th>V1</th>\n",
       "      <th>RV1</th>\n",
       "      <th>R2</th>\n",
       "      <th>Rsq2</th>\n",
       "      <th>V2</th>\n",
       "      <th>RV2</th>\n",
       "      <th>R3</th>\n",
       "      <th>...</th>\n",
       "      <th>V23</th>\n",
       "      <th>RV23</th>\n",
       "      <th>R24</th>\n",
       "      <th>Rsq24</th>\n",
       "      <th>V24</th>\n",
       "      <th>RV24</th>\n",
       "      <th>R25</th>\n",
       "      <th>Rsq25</th>\n",
       "      <th>V25</th>\n",
       "      <th>RV25</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001598</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.009787</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.039106</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.001789</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.016071</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          y  R1  Rsq1  V1  RV1  R2  Rsq2  V2  RV2  R3  ...   V23  RV23  R24  \\\n",
       "0  0.001598 NaN   NaN NaN  NaN NaN   NaN NaN  NaN NaN  ...   NaN   NaN  NaN   \n",
       "1 -0.009787 NaN   NaN NaN  NaN NaN   NaN NaN  NaN NaN  ...   NaN   NaN  NaN   \n",
       "2 -0.039106 NaN   NaN NaN  NaN NaN   NaN NaN  NaN NaN  ...   NaN   NaN  NaN   \n",
       "3  0.001789 NaN   NaN NaN  NaN NaN   NaN NaN  NaN NaN  ...   NaN   NaN  NaN   \n",
       "4 -0.016071 NaN   NaN NaN  NaN NaN   NaN NaN  NaN NaN  ...   NaN   NaN  NaN   \n",
       "\n",
       "   Rsq24  V24  RV24  R25  Rsq25  V25  RV25  \n",
       "0    NaN  NaN   NaN  NaN    NaN  NaN   NaN  \n",
       "1    NaN  NaN   NaN  NaN    NaN  NaN   NaN  \n",
       "2    NaN  NaN   NaN  NaN    NaN  NaN   NaN  \n",
       "3    NaN  NaN   NaN  NaN    NaN  NaN   NaN  \n",
       "4    NaN  NaN   NaN  NaN    NaN  NaN   NaN  \n",
       "\n",
       "[5 rows x 101 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80    -0.011285\n",
       "81    -0.003307\n",
       "82    -0.006207\n",
       "83     0.013569\n",
       "84    -0.019975\n",
       "85    -0.017346\n",
       "86     0.001324\n",
       "87     0.012120\n",
       "88    -0.007512\n",
       "89    -0.008007\n",
       "90    -0.022556\n",
       "91     0.022851\n",
       "92     0.010838\n",
       "93     0.017287\n",
       "94     0.008819\n",
       "95    -0.009595\n",
       "96    -0.009258\n",
       "97    -0.018688\n",
       "98    -0.007529\n",
       "99    -0.014726\n",
       "100    0.016304\n",
       "Name: Return, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[100-20:100,\"Return\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we create a DataFrame that holds the recent volatility of the ETF's returns, as measured by the standard deviation of a sliding window of the past 20 days' returns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "vol_df = pd.DataFrame(data = df[['Return']])\n",
    "\n",
    "for i in range(K+1,n): \n",
    "    # TODO: create the code to assign the standard deviation of the return from the time period starting \n",
    "    # 20 days before day i, up to the day before day i, to the ith row of `vol_df`\n",
    "    vol_df.loc[i, 'vol'] = np.std(df.loc[i-20:i-1,\"Return\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a quick look at the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Return</th>\n",
       "      <th>vol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0.016304</td>\n",
       "      <td>0.013069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>-0.017157</td>\n",
       "      <td>0.013615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>0.001133</td>\n",
       "      <td>0.014007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>0.034194</td>\n",
       "      <td>0.014008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>0.000657</td>\n",
       "      <td>0.015792</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Return       vol\n",
       "100  0.016304  0.013069\n",
       "101 -0.017157  0.013615\n",
       "102  0.001133  0.014007\n",
       "103  0.034194  0.014008\n",
       "104  0.000657  0.015792"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vol_df.iloc[100:105,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our data, we can start thinking about training a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for training, we'll use all the data except for the first K days, for which the predictors' values are NaNs\n",
    "model = model_df.iloc[K:n,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25   -0.001534\n",
       "26    0.013608\n",
       "27   -0.021004\n",
       "28    0.001990\n",
       "29   -0.020309\n",
       "30    0.005859\n",
       "31    0.011425\n",
       "32   -0.014840\n",
       "33   -0.005171\n",
       "34   -0.021469\n",
       "35   -0.002540\n",
       "36    0.011808\n",
       "37   -0.020137\n",
       "38   -0.003620\n",
       "39    0.020978\n",
       "40    0.009642\n",
       "41    0.007276\n",
       "42    0.000678\n",
       "43    0.018723\n",
       "44   -0.009300\n",
       "45   -0.019781\n",
       "46   -0.001254\n",
       "47    0.029224\n",
       "48   -0.004880\n",
       "49   -0.011368\n",
       "50   -0.014206\n",
       "51    0.023330\n",
       "52    0.046715\n",
       "53    0.004057\n",
       "54   -0.001063\n",
       "55    0.016393\n",
       "56    0.006075\n",
       "57    0.016031\n",
       "58    0.006967\n",
       "59   -0.010582\n",
       "60   -0.005759\n",
       "61    0.001035\n",
       "62   -0.016739\n",
       "63    0.011349\n",
       "64    0.005819\n",
       "Name: y, dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.iloc[:40,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell below, first split the data into train and test sets, and then split off the targets from the predictors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train and test sets\n",
    "train_size = 2.0/3.0\n",
    "breakpoint = round(nrow(model) * train_size)\n",
    "\n",
    "# TODO: fill in the code to split off the chunk of data up to the breakpoint as the training set, and\n",
    "# assign the rest as the test set.\n",
    "training_data = model.iloc[:breakpoint,:]\n",
    "test_data = model.iloc[breakpoint:,:]\n",
    "\n",
    "# TODO: Split training data and test data into targets (Y) and predictors (X), for the training set and the test set\n",
    "X_train = training_data.iloc[:,1:]\n",
    "Y_train = training_data.iloc[:,0]\n",
    "X_test = test_data.iloc[:,1:]\n",
    "Y_test = test_data.iloc[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, now that we have our data, let's train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[06:02:41] WARNING: /workspace/src/learner.cc:480: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# DMatrix is a internal data structure that used by XGBoost which is optimized for both memory efficiency \n",
    "# and training speed. \n",
    "dtrain = xgb.DMatrix(X_train, Y_train)\n",
    "\n",
    "# Train the XGBoost model\n",
    "param = { 'max_depth':20, 'silent':1 }\n",
    "num_round = 20\n",
    "xgModel = xgb.train(param, dtrain, num_round)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's predict the returns for the S&P 500 ETF in both the train and test periods. If the model is successful, what should the train and test accuracies look like? What would be a key sign that the model has overfit the training data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Todo: Before you run the next cell, write down what you expect to see if the model is overfit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MSE of training is good, but on testing is bad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the predictions on the test data\n",
    "preds_train = xgModel.predict(xgb.DMatrix(X_train))\n",
    "preds_test = xgModel.predict(xgb.DMatrix(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's quickly look at the mean squared error of the predictions on the training and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Calculate the mean squared error on the training set\n",
    "msetrain = np.mean((preds_train-Y_train)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Calculate the mean squared error on the test set\n",
    "msetest = np.mean((preds_test-Y_test)**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like the mean squared error on the test set is an order of magnitude greater than on the training set. Not a good sign. Now let's do some quick calculations to gauge how this would translate into performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f462a2a6978>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# combine prediction arrays into a single list\n",
    "predictions = c(preds_train, preds_test)\n",
    "responses = c(Y_train, Y_test)\n",
    "\n",
    "# as a holding size, we'll take predicted return divided by return variance\n",
    "# this is mean-variance optimization with a single asset\n",
    "vols = vol_df.loc[K:n,'vol']\n",
    "position_size = predictions / vols ** 2\n",
    "\n",
    "# TODO: Calculate pnl. Pnl in each time period is holding * realized return.\n",
    "performance = position_size*responses\n",
    "\n",
    "# plot simulated performance\n",
    "plt.plot(np.cumsum(performance))\n",
    "plt.ylabel('Simulated Performance')\n",
    "plt.axvline(x=breakpoint, c = 'r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our simulated returns accumulate throughout the training period, but they are absolutely flat in the testing period. The model has no predictive power whatsoever in the out-of-sample period.\n",
    "\n",
    "Can you think of a few reasons our simulation of performance is unrealistic?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Answer the above question."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "If you need a little assistance, check out the [solution](overfitting_exercise_solution.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
